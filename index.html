<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TSCnet:A Text-driven Semantic-level Controllable Module for Personalized Low-Light Image Enhancement</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
  

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TSCnet:A Text-driven Semantic-level Controllable Module for Personalized Low-Light Image Enhancement</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">  
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Miao Zhang</a><sup>†</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Jun Yin</a><sup>†</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Pengyu Zeng</a>,</span>
                                    <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Yiqing Shen</a>,</span>
                                                        <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Shuai Lu</a><sup>*</sup>
                                                                            <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Xueqian Wang</a>,</span>
                    
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Shenzhen International Graduate School
Tsinghua University</span>
                    <span class="eql-cntrb"><small><br><sup>†</sup>Indicates Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Corresponding Author</small></span>
                  </div>


            
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Low-light image enhancement through deep learning can improve noise reduction and visibility. However, existing methods often lack the ability to perform semantic-level, quantitative brightness adjustments, limiting their capacity for personalized lighting control. To address these limitations, we propose a novel framework that utilizes Large Language Model (LLM) capable of interpreting natural language prompt to identify target objects and specify brightness modifications. The framework then employs a Retinex-based Reasoning Segment (RRS) module to generate accurate target localization masks. Concurrently, a Text-based Brightness Controllable (TBC) module applies precise brightness adjustments based on the natural language input. To ensure seamless integration of these components, we introduce an Adaptive Contextual Compensation (ACC) module, which synthesizes multi-source input conditions, guiding a conditional diffusion model to perform accurate lighting adjustments while maintaining overall image coherence. Experimental results on benchmark datasets demonstrate the system's superior performance in enhancing visibility, maintaining natural color balance, and amplifying fine details without introducing artifacts. Our framework also exhibits strong generalization capabilities, enabling complex, semantic-level and personalized lighting adjustments through natural language interactions across various scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TSCnet: A Text-driven Semantic-level Controllable Module for Personalized Low-Light Image Enhancement</title>
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <style>
    /* CSS for the image comparison slider */
    .comparison-container {
        position: relative;
        width: 100%;
        max-width: 600px;
        margin: 0 auto;
    }
    .comparison-image {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: auto;
        overflow: hidden;
    }
    .comparison-image img {
        display: block;
        width: 100%;
    }
    .slider-bar {
        position: absolute;
        top: 0;
        bottom: 0;
        left: 50%;
        width: 3px;
        background-color: white;
        cursor: ew-resize;
    }
  </style>
</head>
<body>
  
<!-- Other sections of the page -->

<!-- Image comparison slider -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="comparison-container" id="comparison-container">
        <div class="comparison-image" style="clip: rect(0, 50%, auto, 0);">
          <img src="MEF.png" alt="Low Light Image">
        </div>
        <div class="comparison-image">
          <img src="DICM.png" alt="Bright Image">
        </div>
        <div class="slider-bar" id="slider-bar"></div>
      </div>
    </div>
  </div>
</section>

<!-- End image comparison slider -->

<!-- JavaScript for the image comparison slider -->
<script>
    const container = document.getElementById("comparison-container");
    const slider = document.getElementById("slider-bar");
    const image = container.querySelector(".comparison-image:first-child");

    container.addEventListener("mousemove", (e) => {
        const rect = container.getBoundingClientRect();
        const xPos = e.clientX - rect.left;
        const width = rect.width;
        const percent = (xPos / width) * 100;
        image.style.clip = `rect(0, ${percent}%, auto, 0)`;
        slider.style.left = `${percent}%`;
    });
</script>

<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the design of this website, we just ask that you link back to this page in the footer. 
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>



  
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="intro1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">The overview of low light enhance tasks.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="framework2.png" lt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">The overview of our method, including the RRS Module, TBC Module, ACC Module and diffusion part.
        </h2>
      </div>
     <div class="item">
      <!-- Your image here -->
      <img src="framework_selective.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">The architecture of ACC Module
      </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Image carouse2 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="lol1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">Visual comparison with other state-of-the-art methods on LOL.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="lol2.png" lt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">Visual comparison with other state-of-the-art methods on LOL2.
        </h2>
      </div>
     <div class="item">
      <!-- Your image here -->
      <img src="DICM.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">Visual comparison with other state-of-the-art methods on DICM.
      </h2>
     </div>
      <div class="item">
      <!-- Your image here -->
      <img src="LOM.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">Visual comparison with other state-of-the-art methods on LOM.
      </h2>
     </div>
      <div class="item">
      <!-- Your image here -->
      <img src="MEF.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">Visual comparison with other state-of-the-art methods on MEF.
      </h2>
     </div>
      <div class="item">
      <!-- Your image here -->
      <img src="REAL.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">Visual comparison with other state-of-the-art methods on REAL.
      </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->
  
<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <div class="item has-text-centered">
        <img src="local_enhance.png" alt="MY ALT TEXT" />
        <!-- Subtitle text container with centered text -->
        <p class="subtitle">
          Results of different tasks, Task A and B aimed at decreasing it and some others aimed at increasing brightness, covering a range of scenes such
          as stage performances, everyday environments, and medical images. The tasks, labeled A through E, involve modifying the brightness of a masked object
          or area (main character, lady, blackboard, side representing evil, left lung) by a percentage ranging from 10% to 40%.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Single Image Display -->

<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <div class="item has-text-centered">
        <img src="Flexible_Adjustment.png" alt="MY ALT TEXT" />
        <!-- Subtitle text container with centered text -->
        <p class="subtitle">
         The application of natural language processing enables complex lighting adjustments in images. 
          In each task, natural language instructions are used to brighten both target and background lighting adjustments, 
          all driven by linguistic input. 
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Single Image Display -->

<!-- Single Image Display -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Single image container -->
      <div class="item has-text-centered">
        <img src="PR_darkface_all.png" alt="MY ALT TEXT" />
        <!-- Subtitle text container with centered text -->
        <p class="subtitle">
Face detection performance in low-light conditions is shown across different methods. The figure  presents visual comparisons of face detection, using various enhancement techniques combined with DSFD. The "Ours + DSFD" delivers the clearest and most accurate results compared to raw input, EnlightenGAN, KinD++, LLflow, and ZeroDCE.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Single Image Display -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
